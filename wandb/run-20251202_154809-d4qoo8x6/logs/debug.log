2025-12-02 15:48:09,196 INFO    MainThread:36288 [wandb_setup.py:_flush():80] Current SDK version is 0.23.0
2025-12-02 15:48:09,196 INFO    MainThread:36288 [wandb_setup.py:_flush():80] Configure stats pid to 36288
2025-12-02 15:48:09,196 INFO    MainThread:36288 [wandb_setup.py:_flush():80] Loading settings from C:\Users\maria\.config\wandb\settings
2025-12-02 15:48:09,196 INFO    MainThread:36288 [wandb_setup.py:_flush():80] Loading settings from C:\Users\maria\Desktop\SAPIENZA\LEZIONI\FUNDATION OF DATA SCIENCE\Human Activity Recognition\FDS_PROJECT\wandb\settings
2025-12-02 15:48:09,196 INFO    MainThread:36288 [wandb_setup.py:_flush():80] Loading settings from environment variables
2025-12-02 15:48:09,196 INFO    MainThread:36288 [wandb_init.py:setup_run_log_directory():713] Logging user logs to .\wandb\run-20251202_154809-d4qoo8x6\logs\debug.log
2025-12-02 15:48:09,196 INFO    MainThread:36288 [wandb_init.py:setup_run_log_directory():714] Logging internal logs to .\wandb\run-20251202_154809-d4qoo8x6\logs\debug-internal.log
2025-12-02 15:48:09,196 INFO    MainThread:36288 [wandb_init.py:init():840] calling init triggers
2025-12-02 15:48:09,196 INFO    MainThread:36288 [wandb_init.py:init():845] wandb.init called with sweep_config: {'dataset.batch_size': 64, 'dataset.val_split': 0.18497385674059347, 'net.depth': 1, 'net.optimizer._target_': 'torch.optim.SGD', 'net.optimizer.lr': 0.0008323644741809538, 'net.rnn_block.hidden_size': 64, 'net.rnn_block.num_layers': 3, 'net.width': 128, 'trainer.max_epochs': 148}
config: {'_wandb': {}}
2025-12-02 15:48:09,196 INFO    MainThread:36288 [wandb_init.py:init():888] starting backend
2025-12-02 15:48:11,500 INFO    MainThread:36288 [wandb_init.py:init():891] sending inform_init request
2025-12-02 15:48:11,561 INFO    MainThread:36288 [wandb_init.py:init():899] backend started and connected
2025-12-02 15:48:11,561 INFO    MainThread:36288 [wandb_run.py:_config_callback():1385] config_cb None None {'dataset.batch_size': 64, 'dataset.val_split': 0.18497385674059347, 'net.depth': 1, 'net.optimizer._target_': 'torch.optim.SGD', 'net.optimizer.lr': 0.0008323644741809538, 'net.rnn_block.hidden_size': 64, 'net.rnn_block.num_layers': 3, 'net.width': 128, 'trainer.max_epochs': 148}
2025-12-02 15:48:11,562 INFO    MainThread:36288 [wandb_init.py:init():969] updated telemetry
2025-12-02 15:48:11,604 INFO    MainThread:36288 [wandb_init.py:init():993] communicating run to backend with 90.0 second timeout
2025-12-02 15:48:12,495 INFO    MainThread:36288 [wandb_init.py:init():1040] starting run threads in backend
2025-12-02 15:48:12,588 INFO    MainThread:36288 [wandb_run.py:_console_start():2504] atexit reg
2025-12-02 15:48:12,588 INFO    MainThread:36288 [wandb_run.py:_redirect():2352] redirect: wrap_raw
2025-12-02 15:48:12,588 INFO    MainThread:36288 [wandb_run.py:_redirect():2421] Wrapping output streams.
2025-12-02 15:48:12,588 INFO    MainThread:36288 [wandb_run.py:_redirect():2444] Redirects installed.
2025-12-02 15:48:12,592 INFO    MainThread:36288 [wandb_init.py:init():1080] run started, returning control to user process
2025-12-02 15:48:12,730 INFO    MainThread:36288 [wandb_run.py:_config_callback():1385] config_cb None None {'cfg': "{'depth': 1, 'width': 128, 'num_classes': 6, 'block': {'_target_': 'net.cnn.ConvBlock', 'in_channels': '${net.width}', 'out_channels': '${net.width}', 'kernel_size': 3, 'pool_size': 2}, 'embed': {'_target_': 'net.cnn.ConvAutoencoder', 'in_channels': 9, 'encoded_channels': '${net.width}', 'kernel_size': 3, 'pool_size': 2}, 'unembed': {'_target_': 'torch.nn.LazyLinear', 'out_features': 6}, 'optimizer': {'_target_': 'torch.optim.SGD', 'lr': 0.0008323644741809538, 'weight_decay': 0.0}, 'rnn_block': {'_target_': 'net.rnn.LSTMBlock', 'input_size': '${net.width}', 'hidden_size': 64, 'num_layers': 3, 'dropout': 0.1, 'bidirectional': False}}"}
