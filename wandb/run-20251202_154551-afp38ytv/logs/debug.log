2025-12-02 15:45:51,344 INFO    MainThread:43624 [wandb_setup.py:_flush():80] Current SDK version is 0.23.0
2025-12-02 15:45:51,344 INFO    MainThread:43624 [wandb_setup.py:_flush():80] Configure stats pid to 43624
2025-12-02 15:45:51,344 INFO    MainThread:43624 [wandb_setup.py:_flush():80] Loading settings from C:\Users\maria\.config\wandb\settings
2025-12-02 15:45:51,344 INFO    MainThread:43624 [wandb_setup.py:_flush():80] Loading settings from C:\Users\maria\Desktop\SAPIENZA\LEZIONI\FUNDATION OF DATA SCIENCE\Human Activity Recognition\FDS_PROJECT\wandb\settings
2025-12-02 15:45:51,344 INFO    MainThread:43624 [wandb_setup.py:_flush():80] Loading settings from environment variables
2025-12-02 15:45:51,344 INFO    MainThread:43624 [wandb_init.py:setup_run_log_directory():713] Logging user logs to .\wandb\run-20251202_154551-afp38ytv\logs\debug.log
2025-12-02 15:45:51,344 INFO    MainThread:43624 [wandb_init.py:setup_run_log_directory():714] Logging internal logs to .\wandb\run-20251202_154551-afp38ytv\logs\debug-internal.log
2025-12-02 15:45:51,344 INFO    MainThread:43624 [wandb_init.py:init():840] calling init triggers
2025-12-02 15:45:51,344 INFO    MainThread:43624 [wandb_init.py:init():845] wandb.init called with sweep_config: {'dataset.batch_size': 32, 'dataset.val_split': 0.15044173087118096, 'net.depth': 1, 'net.optimizer._target_': 'torch.optim.SGD', 'net.optimizer.lr': 0.0008679321784409911, 'net.rnn_block.hidden_size': 128, 'net.rnn_block.num_layers': 3, 'net.width': 128, 'trainer.max_epochs': 129}
config: {'_wandb': {}}
2025-12-02 15:45:51,344 INFO    MainThread:43624 [wandb_init.py:init():888] starting backend
2025-12-02 15:45:53,634 INFO    MainThread:43624 [wandb_init.py:init():891] sending inform_init request
2025-12-02 15:45:53,706 INFO    MainThread:43624 [wandb_init.py:init():899] backend started and connected
2025-12-02 15:45:53,707 INFO    MainThread:43624 [wandb_run.py:_config_callback():1385] config_cb None None {'dataset.batch_size': 32, 'dataset.val_split': 0.15044173087118096, 'net.depth': 1, 'net.optimizer._target_': 'torch.optim.SGD', 'net.optimizer.lr': 0.0008679321784409911, 'net.rnn_block.hidden_size': 128, 'net.rnn_block.num_layers': 3, 'net.width': 128, 'trainer.max_epochs': 129}
2025-12-02 15:45:53,707 INFO    MainThread:43624 [wandb_init.py:init():969] updated telemetry
2025-12-02 15:45:53,750 INFO    MainThread:43624 [wandb_init.py:init():993] communicating run to backend with 90.0 second timeout
2025-12-02 15:45:54,754 INFO    MainThread:43624 [wandb_init.py:init():1040] starting run threads in backend
2025-12-02 15:45:54,840 INFO    MainThread:43624 [wandb_run.py:_console_start():2504] atexit reg
2025-12-02 15:45:54,840 INFO    MainThread:43624 [wandb_run.py:_redirect():2352] redirect: wrap_raw
2025-12-02 15:45:54,841 INFO    MainThread:43624 [wandb_run.py:_redirect():2421] Wrapping output streams.
2025-12-02 15:45:54,841 INFO    MainThread:43624 [wandb_run.py:_redirect():2444] Redirects installed.
2025-12-02 15:45:54,844 INFO    MainThread:43624 [wandb_init.py:init():1080] run started, returning control to user process
2025-12-02 15:45:54,949 INFO    MainThread:43624 [wandb_run.py:_config_callback():1385] config_cb None None {'cfg': "{'depth': 1, 'width': 128, 'num_classes': 6, 'block': {'_target_': 'net.cnn.ConvBlock', 'in_channels': '${net.width}', 'out_channels': '${net.width}', 'kernel_size': 3, 'pool_size': 2}, 'embed': {'_target_': 'net.cnn.ConvAutoencoder', 'in_channels': 9, 'encoded_channels': '${net.width}', 'kernel_size': 3, 'pool_size': 2}, 'unembed': {'_target_': 'torch.nn.LazyLinear', 'out_features': 6}, 'optimizer': {'_target_': 'torch.optim.SGD', 'lr': 0.0008679321784409911, 'weight_decay': 0.0}, 'rnn_block': {'_target_': 'net.rnn.LSTMBlock', 'input_size': '${net.width}', 'hidden_size': 128, 'num_layers': 3, 'dropout': 0.1, 'bidirectional': False}}"}
2025-12-02 15:47:44,090 INFO    MainThread:43624 [wandb_run.py:_config_callback():1385] config_cb None None {'cfg': "{'depth': 1, 'width': 128, 'num_classes': 6, 'block': {'_target_': 'net.cnn.ConvBlock', 'in_channels': '${net.width}', 'out_channels': '${net.width}', 'kernel_size': 3, 'pool_size': 2}, 'embed': {'_target_': 'net.cnn.ConvAutoencoder', 'in_channels': 9, 'encoded_channels': '${net.width}', 'kernel_size': 3, 'pool_size': 2}, 'unembed': {'_target_': 'torch.nn.LazyLinear', 'out_features': 6}, 'optimizer': {'_target_': 'torch.optim.SGD', 'lr': 0.0008679321784409911, 'weight_decay': 0.0}, 'rnn_block': {'_target_': 'net.rnn.LSTMBlock', 'input_size': '${net.width}', 'hidden_size': 128, 'num_layers': 3, 'dropout': 0.1, 'bidirectional': False}}"}
2025-12-02 15:47:56,586 INFO    MainThread:43624 [wandb_run.py:_config_callback():1385] config_cb None None {'seed': 42, 'net': {'depth': 1, 'width': 128, 'num_classes': 6, 'block': {'_target_': 'net.cnn.ConvBlock', 'in_channels': 128, 'out_channels': 128, 'kernel_size': 3, 'pool_size': 2}, 'embed': {'_target_': 'net.cnn.ConvAutoencoder', 'in_channels': 9, 'encoded_channels': 128, 'kernel_size': 3, 'pool_size': 2}, 'unembed': {'_target_': 'torch.nn.LazyLinear', 'out_features': 6}, 'optimizer': {'_target_': 'torch.optim.SGD', 'lr': 0.0008679321784409911, 'weight_decay': 0.0}, 'rnn_block': {'_target_': 'net.rnn.LSTMBlock', 'input_size': 128, 'hidden_size': 128, 'num_layers': 3, 'dropout': 0.1, 'bidirectional': False}}, 'trainer': {'max_epochs': 129, 'log_every_n_steps': 10}, 'dataset': {'data_dir': './data', 'batch_size': 32, 'val_split': 0.15044173087118096}, 'wandb': {'project': 'FDS_PROJECT', 'entity': 'catairu-sapienza-universit-di-roma', 'name': 'max_epochs{max_epochs}_bs{batch_size}_valsplit{val_split}_depth{depth}_width{width}_opt{optimizer._target_}_lr{optimizer.lr}_hsize{rnn_block.hidden_size}_nlayers{rnn_block.num_layers}'}, 'info': {'num_params': 402959}}
2025-12-02 15:47:56,594 INFO    wandb-AsyncioManager-main:43624 [service_client.py:_forward_responses():80] Reached EOF.
2025-12-02 15:47:56,595 INFO    wandb-AsyncioManager-main:43624 [mailbox.py:close():137] Closing mailbox, abandoning 1 handles.
