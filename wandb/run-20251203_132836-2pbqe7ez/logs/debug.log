2025-12-03 13:28:36,246 INFO    MainThread:32788 [wandb_setup.py:_flush():80] Current SDK version is 0.23.0
2025-12-03 13:28:36,246 INFO    MainThread:32788 [wandb_setup.py:_flush():80] Configure stats pid to 32788
2025-12-03 13:28:36,247 INFO    MainThread:32788 [wandb_setup.py:_flush():80] Loading settings from C:\Users\maria\.config\wandb\settings
2025-12-03 13:28:36,247 INFO    MainThread:32788 [wandb_setup.py:_flush():80] Loading settings from C:\Users\maria\Desktop\SAPIENZA\LEZIONI\FUNDATION OF DATA SCIENCE\Human Activity Recognition\FDS_PROJECT\wandb\settings
2025-12-03 13:28:36,247 INFO    MainThread:32788 [wandb_setup.py:_flush():80] Loading settings from environment variables
2025-12-03 13:28:36,247 INFO    MainThread:32788 [wandb_init.py:setup_run_log_directory():713] Logging user logs to .\wandb\run-20251203_132836-2pbqe7ez\logs\debug.log
2025-12-03 13:28:36,248 INFO    MainThread:32788 [wandb_init.py:setup_run_log_directory():714] Logging internal logs to .\wandb\run-20251203_132836-2pbqe7ez\logs\debug-internal.log
2025-12-03 13:28:36,248 INFO    MainThread:32788 [wandb_init.py:init():840] calling init triggers
2025-12-03 13:28:36,248 INFO    MainThread:32788 [wandb_init.py:init():845] wandb.init called with sweep_config: {'dataset.batch_size': 64, 'dataset.val_split': 0.14861831789940205, 'net.depth': 1, 'net.optimizer._target_': 'torch.optim.Adam', 'net.optimizer.lr': 0.0004932486536034722, 'net.rnn_block.hidden_size': 512, 'net.rnn_block.num_layers': 2, 'net.width': 32, 'trainer.max_epochs': 249}
config: {'_wandb': {}}
2025-12-03 13:28:36,248 INFO    MainThread:32788 [wandb_init.py:init():888] starting backend
2025-12-03 13:28:38,557 INFO    MainThread:32788 [wandb_init.py:init():891] sending inform_init request
2025-12-03 13:28:38,699 INFO    MainThread:32788 [wandb_init.py:init():899] backend started and connected
2025-12-03 13:28:38,699 INFO    MainThread:32788 [wandb_run.py:_config_callback():1385] config_cb None None {'dataset.batch_size': 64, 'dataset.val_split': 0.14861831789940205, 'net.depth': 1, 'net.optimizer._target_': 'torch.optim.Adam', 'net.optimizer.lr': 0.0004932486536034722, 'net.rnn_block.hidden_size': 512, 'net.rnn_block.num_layers': 2, 'net.width': 32, 'trainer.max_epochs': 249}
2025-12-03 13:28:38,700 INFO    MainThread:32788 [wandb_init.py:init():969] updated telemetry
2025-12-03 13:28:38,758 INFO    MainThread:32788 [wandb_init.py:init():993] communicating run to backend with 90.0 second timeout
2025-12-03 13:28:39,738 INFO    MainThread:32788 [wandb_init.py:init():1040] starting run threads in backend
2025-12-03 13:28:39,874 INFO    MainThread:32788 [wandb_run.py:_console_start():2504] atexit reg
2025-12-03 13:28:39,874 INFO    MainThread:32788 [wandb_run.py:_redirect():2352] redirect: wrap_raw
2025-12-03 13:28:39,874 INFO    MainThread:32788 [wandb_run.py:_redirect():2421] Wrapping output streams.
2025-12-03 13:28:39,874 INFO    MainThread:32788 [wandb_run.py:_redirect():2444] Redirects installed.
2025-12-03 13:28:39,879 INFO    MainThread:32788 [wandb_init.py:init():1080] run started, returning control to user process
2025-12-03 13:28:39,888 INFO    MainThread:32788 [wandb_run.py:_config_callback():1385] config_cb None None {'cfg': "{'depth': 1, 'width': 32, 'num_classes': 6, 'block': {'_target_': 'net.cnn.ConvBlock', 'in_channels': '${net.width}', 'out_channels': '${net.width}', 'kernel_size': 3, 'pool_size': 2}, 'embed': {'_target_': 'net.cnn.ConvAutoencoder', 'in_channels': 9, 'encoded_channels': '${net.width}', 'kernel_size': 3, 'pool_size': 2}, 'unembed': {'_target_': 'torch.nn.LazyLinear', 'out_features': 6}, 'optimizer': {'_target_': 'torch.optim.Adam', 'lr': 0.0004932486536034722, 'weight_decay': 0.0}, 'rnn_block': {'_target_': 'net.rnn.LSTMBlock', 'input_size': 64, 'hidden_size': 512, 'num_layers': 2, 'dropout': 0.1, 'bidirectional': False}}"}
2025-12-03 13:32:57,162 INFO    wandb-AsyncioManager-main:32788 [service_client.py:_forward_responses():80] Reached EOF.
2025-12-03 13:32:57,162 INFO    wandb-AsyncioManager-main:32788 [mailbox.py:close():137] Closing mailbox, abandoning 1 handles.
