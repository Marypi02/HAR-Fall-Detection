_target_: net.rnn.LSTMBlock 
input_size: 64
hidden_size: 128
num_layers: 2
dropout: 0.25 # 0.1 # % di neuroni disattivati causalmente per ogni batch per evitare la co-dipendenza e forzare la ridondanza nell'apprendimento
bidirectional: False
